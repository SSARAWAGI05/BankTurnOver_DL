{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/JAISHREERAM/Documents/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : CreditScore\n",
      "850    233\n",
      "678     63\n",
      "655     54\n",
      "705     53\n",
      "667     53\n",
      "      ... \n",
      "404      1\n",
      "351      1\n",
      "365      1\n",
      "417      1\n",
      "419      1\n",
      "Name: count, Length: 460, dtype: int64\n",
      "Geography : Geography\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: count, dtype: int64\n",
      "Gender : Gender\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: count, dtype: int64\n",
      "Age : Age\n",
      "37    478\n",
      "38    477\n",
      "35    474\n",
      "36    456\n",
      "34    447\n",
      "     ... \n",
      "92      2\n",
      "82      1\n",
      "88      1\n",
      "85      1\n",
      "83      1\n",
      "Name: count, Length: 70, dtype: int64\n",
      "Tenure : Tenure\n",
      "2     1048\n",
      "1     1035\n",
      "7     1028\n",
      "8     1025\n",
      "5     1012\n",
      "3     1009\n",
      "4      989\n",
      "9      984\n",
      "6      967\n",
      "10     490\n",
      "0      413\n",
      "Name: count, dtype: int64\n",
      "Balance : Balance\n",
      "0.00         3617\n",
      "130170.82       2\n",
      "105473.74       2\n",
      "85304.27        1\n",
      "159397.75       1\n",
      "             ... \n",
      "81556.89        1\n",
      "112687.69       1\n",
      "108698.96       1\n",
      "238387.56       1\n",
      "130142.79       1\n",
      "Name: count, Length: 6382, dtype: int64\n",
      "NumOfProducts : NumOfProducts\n",
      "1    5084\n",
      "2    4590\n",
      "3     266\n",
      "4      60\n",
      "Name: count, dtype: int64\n",
      "HasCrCard : HasCrCard\n",
      "1    7055\n",
      "0    2945\n",
      "Name: count, dtype: int64\n",
      "IsActiveMember : IsActiveMember\n",
      "1    5151\n",
      "0    4849\n",
      "Name: count, dtype: int64\n",
      "EstimatedSalary : EstimatedSalary\n",
      "24924.92     2\n",
      "101348.88    1\n",
      "55313.44     1\n",
      "72500.68     1\n",
      "182692.80    1\n",
      "            ..\n",
      "120893.07    1\n",
      "188377.21    1\n",
      "55902.93     1\n",
      "4523.74      1\n",
      "38190.78     1\n",
      "Name: count, Length: 9999, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for columns in X.columns:\n",
    "    print(f'{columns} : {X[columns].value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "min_max_columns = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "\n",
    "X[min_max_columns] = scaler.fit_transform(X[min_max_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"NumOfProducts\"] = X[\"NumOfProducts\"]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender       Age  Tenure   Balance  \\\n",
       "0           0.538    France  Female  0.324324     0.2  0.000000   \n",
       "1           0.516     Spain  Female  0.310811     0.1  0.334031   \n",
       "2           0.304    France  Female  0.324324     0.8  0.636357   \n",
       "3           0.698    France  Female  0.283784     0.1  0.000000   \n",
       "4           1.000     Spain  Female  0.337838     0.2  0.500246   \n",
       "...           ...       ...     ...       ...     ...       ...   \n",
       "9995        0.842    France    Male  0.283784     0.5  0.000000   \n",
       "9996        0.332    France    Male  0.229730     1.0  0.228657   \n",
       "9997        0.718    France  Female  0.243243     0.7  0.000000   \n",
       "9998        0.844   Germany    Male  0.324324     0.3  0.299226   \n",
       "9999        0.884    France  Female  0.135135     0.4  0.518708   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0              0.25          1               1         0.506735  \n",
       "1              0.25          0               1         0.562709  \n",
       "2              0.75          1               0         0.569654  \n",
       "3              0.50          0               0         0.469120  \n",
       "4              0.25          1               1         0.395400  \n",
       "...             ...        ...             ...              ...  \n",
       "9995           0.50          1               0         0.481341  \n",
       "9996           0.25          1               1         0.508490  \n",
       "9997           0.25          0               1         0.210390  \n",
       "9998           0.50          1               0         0.464429  \n",
       "9999           0.25          1               0         0.190914  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X[\"Geography\"], prefix='Geography')\n",
    "\n",
    "# Drop the original 'Geography' column and concatenate the dummy variables\n",
    "X = X.drop(\"Geography\", axis=1)\n",
    "X = pd.concat([X, X_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538  Female  0.324324     0.2  0.000000           0.25   \n",
       "1           0.516  Female  0.310811     0.1  0.334031           0.25   \n",
       "2           0.304  Female  0.324324     0.8  0.636357           0.75   \n",
       "3           0.698  Female  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000  Female  0.337838     0.2  0.500246           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842    Male  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332    Male  0.229730     1.0  0.228657           0.25   \n",
       "9997        0.718  Female  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844    Male  0.324324     0.3  0.299226           0.50   \n",
       "9999        0.884  Female  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735              True   \n",
       "1             0               1         0.562709             False   \n",
       "2             1               0         0.569654              True   \n",
       "3             0               0         0.469120              True   \n",
       "4             1               1         0.395400             False   \n",
       "...         ...             ...              ...               ...   \n",
       "9995          1               0         0.481341              True   \n",
       "9996          1               1         0.508490              True   \n",
       "9997          0               1         0.210390              True   \n",
       "9998          1               0         0.464429             False   \n",
       "9999          1               0         0.190914              True   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                 False            False  \n",
       "1                 False             True  \n",
       "2                 False            False  \n",
       "3                 False            False  \n",
       "4                 False             True  \n",
       "...                 ...              ...  \n",
       "9995              False            False  \n",
       "9996              False            False  \n",
       "9997              False            False  \n",
       "9998               True            False  \n",
       "9999              False            False  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc_cols = [\"Geography_France\", \"Geography_Germany\", \"Geography_Spain\"]\n",
    "X[label_enc_cols] = X[label_enc_cols].astype(int)\n",
    "X['Gender'] = X['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000           0.25   \n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "2           0.304       0  0.324324     0.8  0.636357           0.75   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       1  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332       1  0.229730     1.0  0.228657           0.25   \n",
       "9997        0.718       0  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844       1  0.324324     0.3  0.299226           0.50   \n",
       "9999        0.884       0  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735                 1   \n",
       "1             0               1         0.562709                 0   \n",
       "2             1               0         0.569654                 1   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0 = (y==0).sum()\n",
    "count_1 = (y==1).sum()\n",
    "count_0, count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000           0.25   \n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "2           0.304       0  0.324324     0.8  0.636357           0.75   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       1  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332       1  0.229730     1.0  0.228657           0.25   \n",
       "9997        0.718       0  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844       1  0.324324     0.3  0.299226           0.50   \n",
       "9999        0.884       0  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735                 1   \n",
       "1             0               1         0.562709                 0   \n",
       "2             1               0         0.569654                 1   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "0                     0                0       1  \n",
       "1                     0                1       0  \n",
       "2                     0                0       1  \n",
       "3                     0                0       0  \n",
       "4                     0                1       0  \n",
       "...                 ...              ...     ...  \n",
       "9995                  0                0       0  \n",
       "9996                  0                0       0  \n",
       "9997                  0                0       1  \n",
       "9998                  1                0       1  \n",
       "9999                  0                0       0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Oversampling\n",
    "df_0 = df_mod[df_mod['Exited']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.618021</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "6           0.944       1  0.432432     0.7  0.000000           0.50   \n",
       "8           0.302       1  0.351351     0.4  0.566170           0.50   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9993        0.588       1  0.135135     0.7  0.618021           0.25   \n",
       "9994        0.900       0  0.148649     0.2  0.000000           0.50   \n",
       "9995        0.842       1  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332       1  0.229730     1.0  0.228657           0.25   \n",
       "9999        0.884       0  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "1             0               1         0.562709                 0   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "6             1               1         0.050261                 1   \n",
       "8             0               1         0.374680                 1   \n",
       "...         ...             ...              ...               ...   \n",
       "9993          1               0         0.145854                 1   \n",
       "9994          0               0         0.838890                 1   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "1                     0                1       0  \n",
       "3                     0                0       0  \n",
       "4                     0                1       0  \n",
       "6                     0                0       0  \n",
       "8                     0                0       0  \n",
       "...                 ...              ...     ...  \n",
       "9993                  0                0       0  \n",
       "9994                  0                0       0  \n",
       "9995                  0                0       0  \n",
       "9996                  0                0       0  \n",
       "9999                  0                0       0  \n",
       "\n",
       "[7963 rows x 13 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_mod[df_mod['Exited']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.453394</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.458540</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.528513</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.296</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.605982</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.546617</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.352259</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346899</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2037 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000           0.25   \n",
       "2           0.304       0  0.324324     0.8  0.636357           0.75   \n",
       "5           0.590       1  0.351351     0.8  0.453394           0.50   \n",
       "7           0.052       0  0.148649     0.4  0.458540           1.00   \n",
       "16          0.606       1  0.540541     0.1  0.528513           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9981        0.296       1  0.324324     0.3  0.605982           0.25   \n",
       "9982        0.610       0  0.378378     0.7  0.546617           0.25   \n",
       "9991        0.494       0  0.472973     0.4  0.352259           0.25   \n",
       "9997        0.718       0  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844       1  0.324324     0.3  0.299226           0.50   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735                 1   \n",
       "2             1               0         0.569654                 1   \n",
       "5             1               0         0.748797                 0   \n",
       "7             1               0         0.596733                 0   \n",
       "16            1               0         0.025433                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9981          1               1         0.267193                 0   \n",
       "9982          1               0         0.575729                 0   \n",
       "9991          1               0         0.346899                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "0                     0                0       1  \n",
       "2                     0                0       1  \n",
       "5                     0                1       1  \n",
       "7                     1                0       1  \n",
       "16                    1                0       1  \n",
       "...                 ...              ...     ...  \n",
       "9981                  1                0       1  \n",
       "9982                  1                0       1  \n",
       "9991                  0                0       1  \n",
       "9997                  0                0       1  \n",
       "9998                  1                0       1  \n",
       "\n",
       "[2037 rows x 13 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0 = df_0['Exited'].shape[0]\n",
    "count_1 = df_1['Exited'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0, count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.sample(count_0, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 13), (7963, 13))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape, df_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over = pd.concat([df_0, df_1], axis=0)\n",
    "df_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.577018</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>0.654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.505103</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>0.396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.432199</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>0.258</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.829682</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0.508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.575747</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15926 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "6           0.944       1  0.432432     0.7  0.000000           0.50   \n",
       "8           0.302       1  0.351351     0.4  0.566170           0.50   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "8422        0.524       0  0.459459     0.5  0.577018           0.25   \n",
       "5558        0.654       1  0.216216     0.3  0.505103           0.25   \n",
       "5972        0.396       1  0.418919     0.9  0.432199           0.25   \n",
       "5871        0.258       0  0.202703     0.2  0.829682           0.25   \n",
       "1951        0.508       1  0.472973     0.8  0.575747           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "1             0               1         0.562709                 0   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "6             1               1         0.050261                 1   \n",
       "8             0               1         0.374680                 1   \n",
       "...         ...             ...              ...               ...   \n",
       "8422          0               0         0.491502                 0   \n",
       "5558          1               1         0.130487                 0   \n",
       "5972          0               0         0.635117                 0   \n",
       "5871          0               0         0.253840                 1   \n",
       "1951          1               0         0.955028                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "1                     0                1       0  \n",
       "3                     0                0       0  \n",
       "4                     0                1       0  \n",
       "6                     0                0       0  \n",
       "8                     0                0       0  \n",
       "...                 ...              ...     ...  \n",
       "8422                  0                1       1  \n",
       "5558                  1                0       1  \n",
       "5972                  1                0       1  \n",
       "5871                  0                0       1  \n",
       "1951                  0                0       1  \n",
       "\n",
       "[15926 rows x 13 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = df_over.drop(columns=[\"Exited\"])\n",
    "y_over = df_over['Exited']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15926, 12), (15926,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape, y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0\n",
       "3       0\n",
       "4       0\n",
       "6       0\n",
       "8       0\n",
       "       ..\n",
       "8422    1\n",
       "5558    1\n",
       "5972    1\n",
       "5871    1\n",
       "1951    1\n",
       "Name: Exited, Length: 15926, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15926, 12), (15926,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape, y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42, stratify=y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Exited\n",
       " 0    6370\n",
       " 1    6370\n",
       " Name: count, dtype: int64,\n",
       " Exited\n",
       " 0    1593\n",
       " 1    1593\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cifar/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - accuracy: 0.5082 - loss: 0.6951\n",
      "Epoch 2/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.6354 - loss: 0.6580\n",
      "Epoch 3/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.6759 - loss: 0.6233\n",
      "Epoch 4/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.6991 - loss: 0.5942\n",
      "Epoch 5/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7020 - loss: 0.5874\n",
      "Epoch 6/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7231 - loss: 0.5627\n",
      "Epoch 7/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7313 - loss: 0.5523\n",
      "Epoch 8/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7413 - loss: 0.5390\n",
      "Epoch 9/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7419 - loss: 0.5277\n",
      "Epoch 10/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7425 - loss: 0.5240\n",
      "Epoch 11/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7524 - loss: 0.5155\n",
      "Epoch 12/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7630 - loss: 0.5032\n",
      "Epoch 13/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7694 - loss: 0.4954\n",
      "Epoch 14/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7647 - loss: 0.5032\n",
      "Epoch 15/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7659 - loss: 0.4978\n",
      "Epoch 16/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7703 - loss: 0.4846\n",
      "Epoch 17/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7654 - loss: 0.4966\n",
      "Epoch 18/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7701 - loss: 0.4843\n",
      "Epoch 19/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7715 - loss: 0.4888\n",
      "Epoch 20/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7719 - loss: 0.4796\n",
      "Epoch 21/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7741 - loss: 0.4743\n",
      "Epoch 22/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7659 - loss: 0.4832\n",
      "Epoch 23/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7739 - loss: 0.4778\n",
      "Epoch 24/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7751 - loss: 0.4742\n",
      "Epoch 25/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7771 - loss: 0.4731\n",
      "Epoch 26/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7799 - loss: 0.4652\n",
      "Epoch 27/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7802 - loss: 0.4616\n",
      "Epoch 28/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7738 - loss: 0.4705\n",
      "Epoch 29/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7715 - loss: 0.4720\n",
      "Epoch 30/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7784 - loss: 0.4628\n",
      "Epoch 31/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7745 - loss: 0.4681\n",
      "Epoch 32/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7732 - loss: 0.4677\n",
      "Epoch 33/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7790 - loss: 0.4618\n",
      "Epoch 34/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7684 - loss: 0.4703\n",
      "Epoch 35/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7772 - loss: 0.4691\n",
      "Epoch 36/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7727 - loss: 0.4690\n",
      "Epoch 37/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7760 - loss: 0.4638\n",
      "Epoch 38/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7762 - loss: 0.4639\n",
      "Epoch 39/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7720 - loss: 0.4700\n",
      "Epoch 40/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7744 - loss: 0.4653\n",
      "Epoch 41/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7748 - loss: 0.4663\n",
      "Epoch 42/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7773 - loss: 0.4645\n",
      "Epoch 43/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7746 - loss: 0.4649\n",
      "Epoch 44/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7707 - loss: 0.4661\n",
      "Epoch 45/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7768 - loss: 0.4643\n",
      "Epoch 46/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7777 - loss: 0.4617\n",
      "Epoch 47/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7769 - loss: 0.4603\n",
      "Epoch 48/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7804 - loss: 0.4576\n",
      "Epoch 49/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7844 - loss: 0.4533\n",
      "Epoch 50/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7697 - loss: 0.4635\n",
      "Epoch 51/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.7779 - loss: 0.4644\n",
      "Epoch 52/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7685 - loss: 0.4704\n",
      "Epoch 53/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7801 - loss: 0.4555\n",
      "Epoch 54/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7729 - loss: 0.4642\n",
      "Epoch 55/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7779 - loss: 0.4560\n",
      "Epoch 56/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7781 - loss: 0.4552\n",
      "Epoch 57/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7739 - loss: 0.4684\n",
      "Epoch 58/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7756 - loss: 0.4585\n",
      "Epoch 59/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7866 - loss: 0.4558\n",
      "Epoch 60/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7809 - loss: 0.4559\n",
      "Epoch 61/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7725 - loss: 0.4608\n",
      "Epoch 62/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - accuracy: 0.7737 - loss: 0.4594\n",
      "Epoch 63/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.7749 - loss: 0.4673\n",
      "Epoch 64/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.7793 - loss: 0.4552\n",
      "Epoch 65/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7820 - loss: 0.4502\n",
      "Epoch 66/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7753 - loss: 0.4588\n",
      "Epoch 67/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7836 - loss: 0.4534\n",
      "Epoch 68/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.7694 - loss: 0.4668\n",
      "Epoch 69/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.7794 - loss: 0.4563\n",
      "Epoch 70/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7822 - loss: 0.4517\n",
      "Epoch 71/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7725 - loss: 0.4604\n",
      "Epoch 72/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7801 - loss: 0.4577\n",
      "Epoch 73/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7774 - loss: 0.4613\n",
      "Epoch 74/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7785 - loss: 0.4588\n",
      "Epoch 75/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7772 - loss: 0.4556\n",
      "Epoch 76/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7750 - loss: 0.4542\n",
      "Epoch 77/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7734 - loss: 0.4622\n",
      "Epoch 78/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7787 - loss: 0.4528\n",
      "Epoch 79/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7772 - loss: 0.4540\n",
      "Epoch 80/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7759 - loss: 0.4602\n",
      "Epoch 81/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7754 - loss: 0.4610\n",
      "Epoch 82/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7799 - loss: 0.4577\n",
      "Epoch 83/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7738 - loss: 0.4588\n",
      "Epoch 84/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7772 - loss: 0.4616\n",
      "Epoch 85/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7791 - loss: 0.4560\n",
      "Epoch 86/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7764 - loss: 0.4541\n",
      "Epoch 87/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7810 - loss: 0.4537\n",
      "Epoch 88/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7825 - loss: 0.4489\n",
      "Epoch 89/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7751 - loss: 0.4569\n",
      "Epoch 90/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7846 - loss: 0.4568\n",
      "Epoch 91/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7734 - loss: 0.4626\n",
      "Epoch 92/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7800 - loss: 0.4549\n",
      "Epoch 93/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7830 - loss: 0.4485\n",
      "Epoch 94/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7780 - loss: 0.4602\n",
      "Epoch 95/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7807 - loss: 0.4526\n",
      "Epoch 96/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7837 - loss: 0.4493\n",
      "Epoch 97/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7780 - loss: 0.4504\n",
      "Epoch 98/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7760 - loss: 0.4565\n",
      "Epoch 99/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7733 - loss: 0.4567\n",
      "Epoch 100/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7781 - loss: 0.4552\n",
      "Epoch 101/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7731 - loss: 0.4602\n",
      "Epoch 102/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7831 - loss: 0.4495\n",
      "Epoch 103/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7737 - loss: 0.4647\n",
      "Epoch 104/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7709 - loss: 0.4593\n",
      "Epoch 105/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7789 - loss: 0.4556\n",
      "Epoch 106/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7774 - loss: 0.4536\n",
      "Epoch 107/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7884 - loss: 0.4450\n",
      "Epoch 108/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7797 - loss: 0.4535\n",
      "Epoch 109/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7767 - loss: 0.4580\n",
      "Epoch 110/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7823 - loss: 0.4469\n",
      "Epoch 111/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7768 - loss: 0.4511\n",
      "Epoch 112/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7817 - loss: 0.4524\n",
      "Epoch 113/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7781 - loss: 0.4568\n",
      "Epoch 114/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7738 - loss: 0.4592\n",
      "Epoch 115/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7844 - loss: 0.4513\n",
      "Epoch 116/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7804 - loss: 0.4540\n",
      "Epoch 117/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7783 - loss: 0.4556\n",
      "Epoch 118/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7838 - loss: 0.4526\n",
      "Epoch 119/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7804 - loss: 0.4512\n",
      "Epoch 120/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7799 - loss: 0.4534\n",
      "Epoch 121/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7884 - loss: 0.4415\n",
      "Epoch 122/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7866 - loss: 0.4411\n",
      "Epoch 123/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7790 - loss: 0.4569\n",
      "Epoch 124/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7792 - loss: 0.4581\n",
      "Epoch 125/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7811 - loss: 0.4499\n",
      "Epoch 126/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7818 - loss: 0.4520\n",
      "Epoch 127/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7828 - loss: 0.4490\n",
      "Epoch 128/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7904 - loss: 0.4446\n",
      "Epoch 129/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7804 - loss: 0.4565\n",
      "Epoch 130/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7790 - loss: 0.4490\n",
      "Epoch 131/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7835 - loss: 0.4466\n",
      "Epoch 132/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7867 - loss: 0.4426\n",
      "Epoch 133/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7877 - loss: 0.4456\n",
      "Epoch 134/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7786 - loss: 0.4531\n",
      "Epoch 135/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7819 - loss: 0.4488\n",
      "Epoch 136/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7829 - loss: 0.4502\n",
      "Epoch 137/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step - accuracy: 0.7718 - loss: 0.4622\n",
      "Epoch 138/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7858 - loss: 0.4425\n",
      "Epoch 139/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7858 - loss: 0.4483\n",
      "Epoch 140/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7859 - loss: 0.4503\n",
      "Epoch 141/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7836 - loss: 0.4442\n",
      "Epoch 142/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7813 - loss: 0.4571\n",
      "Epoch 143/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7766 - loss: 0.4573\n",
      "Epoch 144/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7780 - loss: 0.4526\n",
      "Epoch 145/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7810 - loss: 0.4506\n",
      "Epoch 146/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7845 - loss: 0.4482\n",
      "Epoch 147/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7827 - loss: 0.4482\n",
      "Epoch 148/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7881 - loss: 0.4412\n",
      "Epoch 149/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7948 - loss: 0.4376\n",
      "Epoch 150/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.7852 - loss: 0.4479\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1593\n",
      "           1       0.76      0.79      0.78      1593\n",
      "\n",
      "    accuracy                           0.77      3186\n",
      "   macro avg       0.77      0.77      0.77      3186\n",
      "weighted avg       0.77      0.77      0.77      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(12,), activation='relu'),\n",
    "    keras.layers.Dense(7, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "y_preds = np.round(y_preds)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.7693 - loss: 0.4604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4614221155643463, 0.770244836807251]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000           0.25   \n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "2           0.304       0  0.324324     0.8  0.636357           0.75   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       1  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332       1  0.229730     1.0  0.228657           0.25   \n",
       "9997        0.718       0  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844       1  0.324324     0.3  0.299226           0.50   \n",
       "9999        0.884       0  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735                 1   \n",
       "1             0               1         0.562709                 0   \n",
       "2             1               0         0.569654                 1   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "0                     0                0       1  \n",
       "1                     0                1       0  \n",
       "2                     0                0       1  \n",
       "3                     0                0       0  \n",
       "4                     0                1       0  \n",
       "...                 ...              ...     ...  \n",
       "9995                  0                0       0  \n",
       "9996                  0                0       0  \n",
       "9997                  0                0       1  \n",
       "9998                  1                0       1  \n",
       "9999                  0                0       0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_temp = df_mod.drop(columns=['Exited'])\n",
    "y_temp = df_mod['Exited']\n",
    "smote = SMOTE(sampling_strategy = 'minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_temp, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=42, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7874 - loss: 0.4458\n",
      "Epoch 2/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7906 - loss: 0.4395\n",
      "Epoch 3/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7895 - loss: 0.4383\n",
      "Epoch 4/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7909 - loss: 0.4381\n",
      "Epoch 5/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7917 - loss: 0.4377\n",
      "Epoch 6/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7893 - loss: 0.4438\n",
      "Epoch 7/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7863 - loss: 0.4396\n",
      "Epoch 8/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7939 - loss: 0.4338\n",
      "Epoch 9/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7924 - loss: 0.4410\n",
      "Epoch 10/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7860 - loss: 0.4401\n",
      "Epoch 11/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7945 - loss: 0.4318\n",
      "Epoch 12/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7864 - loss: 0.4454\n",
      "Epoch 13/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7965 - loss: 0.4322\n",
      "Epoch 14/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7902 - loss: 0.4388\n",
      "Epoch 15/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7879 - loss: 0.4451\n",
      "Epoch 16/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7931 - loss: 0.4323\n",
      "Epoch 17/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7879 - loss: 0.4444\n",
      "Epoch 18/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7967 - loss: 0.4320\n",
      "Epoch 19/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7937 - loss: 0.4389\n",
      "Epoch 20/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7910 - loss: 0.4344\n",
      "Epoch 21/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8021 - loss: 0.4289\n",
      "Epoch 22/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7974 - loss: 0.4305\n",
      "Epoch 23/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7981 - loss: 0.4306\n",
      "Epoch 24/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7934 - loss: 0.4330\n",
      "Epoch 25/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7972 - loss: 0.4337\n",
      "Epoch 26/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7926 - loss: 0.4357\n",
      "Epoch 27/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7976 - loss: 0.4279\n",
      "Epoch 28/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7913 - loss: 0.4341\n",
      "Epoch 29/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7933 - loss: 0.4350\n",
      "Epoch 30/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7911 - loss: 0.4384\n",
      "Epoch 31/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7970 - loss: 0.4288\n",
      "Epoch 32/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7955 - loss: 0.4314\n",
      "Epoch 33/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7993 - loss: 0.4242\n",
      "Epoch 34/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7923 - loss: 0.4336\n",
      "Epoch 35/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7904 - loss: 0.4418\n",
      "Epoch 36/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7990 - loss: 0.4301\n",
      "Epoch 37/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7891 - loss: 0.4351\n",
      "Epoch 38/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7973 - loss: 0.4300\n",
      "Epoch 39/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7978 - loss: 0.4263\n",
      "Epoch 40/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7913 - loss: 0.4390\n",
      "Epoch 41/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7905 - loss: 0.4390\n",
      "Epoch 42/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7908 - loss: 0.4362\n",
      "Epoch 43/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7921 - loss: 0.4322\n",
      "Epoch 44/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7955 - loss: 0.4316\n",
      "Epoch 45/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7970 - loss: 0.4298\n",
      "Epoch 46/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7970 - loss: 0.4279\n",
      "Epoch 47/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7979 - loss: 0.4249\n",
      "Epoch 48/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7983 - loss: 0.4255\n",
      "Epoch 49/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7897 - loss: 0.4354\n",
      "Epoch 50/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7943 - loss: 0.4291\n",
      "Epoch 51/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7988 - loss: 0.4274\n",
      "Epoch 52/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7976 - loss: 0.4233\n",
      "Epoch 53/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7911 - loss: 0.4312\n",
      "Epoch 54/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7928 - loss: 0.4320\n",
      "Epoch 55/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7886 - loss: 0.4343\n",
      "Epoch 56/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7955 - loss: 0.4289\n",
      "Epoch 57/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7954 - loss: 0.4311\n",
      "Epoch 58/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7980 - loss: 0.4237\n",
      "Epoch 59/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7990 - loss: 0.4258\n",
      "Epoch 60/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7970 - loss: 0.4257\n",
      "Epoch 61/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8009 - loss: 0.4221\n",
      "Epoch 62/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8032 - loss: 0.4210\n",
      "Epoch 63/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.8014 - loss: 0.4217\n",
      "Epoch 64/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.8011 - loss: 0.4259\n",
      "Epoch 65/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.8009 - loss: 0.4233\n",
      "Epoch 66/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7859 - loss: 0.4432\n",
      "Epoch 67/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8012 - loss: 0.4166\n",
      "Epoch 68/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7961 - loss: 0.4278\n",
      "Epoch 69/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8029 - loss: 0.4140\n",
      "Epoch 70/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7981 - loss: 0.4329\n",
      "Epoch 71/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8044 - loss: 0.4186\n",
      "Epoch 72/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8009 - loss: 0.4239\n",
      "Epoch 73/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7978 - loss: 0.4206\n",
      "Epoch 74/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.8024 - loss: 0.4245\n",
      "Epoch 75/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.8030 - loss: 0.4177\n",
      "Epoch 76/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.8027 - loss: 0.4156\n",
      "Epoch 77/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8073 - loss: 0.4154\n",
      "Epoch 78/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.8040 - loss: 0.4227\n",
      "Epoch 79/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8016 - loss: 0.4217\n",
      "Epoch 80/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7974 - loss: 0.4317\n",
      "Epoch 81/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7987 - loss: 0.4230\n",
      "Epoch 82/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7993 - loss: 0.4151\n",
      "Epoch 83/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7978 - loss: 0.4284\n",
      "Epoch 84/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7971 - loss: 0.4223\n",
      "Epoch 85/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8007 - loss: 0.4192\n",
      "Epoch 86/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.8042 - loss: 0.4241\n",
      "Epoch 87/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7982 - loss: 0.4221\n",
      "Epoch 88/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7978 - loss: 0.4238\n",
      "Epoch 89/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7995 - loss: 0.4284\n",
      "Epoch 90/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.8013 - loss: 0.4239\n",
      "Epoch 91/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8058 - loss: 0.4154\n",
      "Epoch 92/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7947 - loss: 0.4276\n",
      "Epoch 93/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.8025 - loss: 0.4167\n",
      "Epoch 94/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.8005 - loss: 0.4196\n",
      "Epoch 95/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.8007 - loss: 0.4219\n",
      "Epoch 96/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.8055 - loss: 0.4220\n",
      "Epoch 97/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7979 - loss: 0.4214\n",
      "Epoch 98/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8059 - loss: 0.4125\n",
      "Epoch 99/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7953 - loss: 0.4258\n",
      "Epoch 100/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.8014 - loss: 0.4202\n",
      "Epoch 101/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.8009 - loss: 0.4235\n",
      "Epoch 102/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8006 - loss: 0.4213\n",
      "Epoch 103/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7989 - loss: 0.4177\n",
      "Epoch 104/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.8090 - loss: 0.4085\n",
      "Epoch 105/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8000 - loss: 0.4188\n",
      "Epoch 106/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.8072 - loss: 0.4150\n",
      "Epoch 107/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7976 - loss: 0.4208\n",
      "Epoch 108/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8100 - loss: 0.4098\n",
      "Epoch 109/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8034 - loss: 0.4223\n",
      "Epoch 110/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8056 - loss: 0.4142\n",
      "Epoch 111/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7980 - loss: 0.4255\n",
      "Epoch 112/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7997 - loss: 0.4171\n",
      "Epoch 113/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.8021 - loss: 0.4192\n",
      "Epoch 114/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.8004 - loss: 0.4238\n",
      "Epoch 115/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7978 - loss: 0.4271\n",
      "Epoch 116/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.8046 - loss: 0.4125\n",
      "Epoch 117/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8029 - loss: 0.4225\n",
      "Epoch 118/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.8045 - loss: 0.4139\n",
      "Epoch 119/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.8025 - loss: 0.4206\n",
      "Epoch 120/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8009 - loss: 0.4229\n",
      "Epoch 121/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.8078 - loss: 0.4116\n",
      "Epoch 122/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8047 - loss: 0.4193\n",
      "Epoch 123/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8051 - loss: 0.4226\n",
      "Epoch 124/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8050 - loss: 0.4182\n",
      "Epoch 125/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8036 - loss: 0.4242\n",
      "Epoch 126/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8049 - loss: 0.4188\n",
      "Epoch 127/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8078 - loss: 0.4126\n",
      "Epoch 128/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8003 - loss: 0.4107\n",
      "Epoch 129/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8087 - loss: 0.4084\n",
      "Epoch 130/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8045 - loss: 0.4160\n",
      "Epoch 131/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8012 - loss: 0.4162\n",
      "Epoch 132/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7996 - loss: 0.4237\n",
      "Epoch 133/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7916 - loss: 0.4251\n",
      "Epoch 134/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7938 - loss: 0.4187\n",
      "Epoch 135/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.8051 - loss: 0.4191\n",
      "Epoch 136/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8021 - loss: 0.4196\n",
      "Epoch 137/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8048 - loss: 0.4122\n",
      "Epoch 138/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8073 - loss: 0.4147\n",
      "Epoch 139/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8047 - loss: 0.4146\n",
      "Epoch 140/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8103 - loss: 0.4005\n",
      "Epoch 141/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8021 - loss: 0.4212\n",
      "Epoch 142/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.8026 - loss: 0.4209\n",
      "Epoch 143/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.8047 - loss: 0.4175\n",
      "Epoch 144/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8013 - loss: 0.4158\n",
      "Epoch 145/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.8063 - loss: 0.4171\n",
      "Epoch 146/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.8011 - loss: 0.4214\n",
      "Epoch 147/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8027 - loss: 0.4173\n",
      "Epoch 148/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8050 - loss: 0.4212\n",
      "Epoch 149/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8016 - loss: 0.4152\n",
      "Epoch 150/150\n",
      "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8091 - loss: 0.4091\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80      1593\n",
      "           1       0.83      0.72      0.77      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.79      0.78      0.78      3186\n",
      "weighted avg       0.79      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(12,), activation='relu'),\n",
    "    keras.layers.Dense(7, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dense(4, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "'''\n",
    "model.fit(X_train, y_train, epochs=150)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "y_preds = np.round(y_preds)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258us/step - accuracy: 0.7825 - loss: 0.4469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.442104697227478, 0.784055233001709]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = df_mod.drop('Exited', axis=1)\n",
    "y_3 = df_mod['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_3, y_3, test_size=0.2, random_state=15, stratify=y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train['Exited']\n",
    "    return X_train, y_train    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_1 = df_mod[df_mod['Exited']==1]\n",
    "df_3_0 = df_mod[df_mod['Exited']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.453394</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.458540</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.528513</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.296</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.605982</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.546617</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.352259</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346899</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2037 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0           0.538       0  0.324324     0.2  0.000000           0.25   \n",
       "2           0.304       0  0.324324     0.8  0.636357           0.75   \n",
       "5           0.590       1  0.351351     0.8  0.453394           0.50   \n",
       "7           0.052       0  0.148649     0.4  0.458540           1.00   \n",
       "16          0.606       1  0.540541     0.1  0.528513           0.25   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9981        0.296       1  0.324324     0.3  0.605982           0.25   \n",
       "9982        0.610       0  0.378378     0.7  0.546617           0.25   \n",
       "9991        0.494       0  0.472973     0.4  0.352259           0.25   \n",
       "9997        0.718       0  0.243243     0.7  0.000000           0.25   \n",
       "9998        0.844       1  0.324324     0.3  0.299226           0.50   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "0             1               1         0.506735                 1   \n",
       "2             1               0         0.569654                 1   \n",
       "5             1               0         0.748797                 0   \n",
       "7             1               0         0.596733                 0   \n",
       "16            1               0         0.025433                 0   \n",
       "...         ...             ...              ...               ...   \n",
       "9981          1               1         0.267193                 0   \n",
       "9982          1               0         0.575729                 0   \n",
       "9991          1               0         0.346899                 1   \n",
       "9997          0               1         0.210390                 1   \n",
       "9998          1               0         0.464429                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "0                     0                0       1  \n",
       "2                     0                0       1  \n",
       "5                     0                1       1  \n",
       "7                     1                0       1  \n",
       "16                    1                0       1  \n",
       "...                 ...              ...     ...  \n",
       "9981                  1                0       1  \n",
       "9982                  1                0       1  \n",
       "9991                  0                0       1  \n",
       "9997                  0                0       1  \n",
       "9998                  1                0       1  \n",
       "\n",
       "[2037 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944</td>\n",
       "      <td>1</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.618021</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.838890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "1           0.516       0  0.310811     0.1  0.334031           0.25   \n",
       "3           0.698       0  0.283784     0.1  0.000000           0.50   \n",
       "4           1.000       0  0.337838     0.2  0.500246           0.25   \n",
       "6           0.944       1  0.432432     0.7  0.000000           0.50   \n",
       "8           0.302       1  0.351351     0.4  0.566170           0.50   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9993        0.588       1  0.135135     0.7  0.618021           0.25   \n",
       "9994        0.900       0  0.148649     0.2  0.000000           0.50   \n",
       "9995        0.842       1  0.283784     0.5  0.000000           0.50   \n",
       "9996        0.332       1  0.229730     1.0  0.228657           0.25   \n",
       "9999        0.884       0  0.135135     0.4  0.518708           0.25   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  \\\n",
       "1             0               1         0.562709                 0   \n",
       "3             0               0         0.469120                 1   \n",
       "4             1               1         0.395400                 0   \n",
       "6             1               1         0.050261                 1   \n",
       "8             0               1         0.374680                 1   \n",
       "...         ...             ...              ...               ...   \n",
       "9993          1               0         0.145854                 1   \n",
       "9994          0               0         0.838890                 1   \n",
       "9995          1               0         0.481341                 1   \n",
       "9996          1               1         0.508490                 1   \n",
       "9999          1               0         0.190914                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Exited  \n",
       "1                     0                1       0  \n",
       "3                     0                0       0  \n",
       "4                     0                1       0  \n",
       "6                     0                0       0  \n",
       "8                     0                0       0  \n",
       "...                 ...              ...     ...  \n",
       "9993                  0                0       0  \n",
       "9994                  0                0       0  \n",
       "9995                  0                0       0  \n",
       "9996                  0                0       0  \n",
       "9999                  0                0       0  \n",
       "\n",
       "[7963 rows x 13 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4074, 12) (4074,)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_3_0, df_3_1, 0, 2037)\n",
    "print(X_train.shape, y_train.shape)  # Check shapes\n",
    "print(type(X_train), type(y_train))  # Check types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7744 - loss: 0.4617\n",
      "Epoch 2/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7691 - loss: 0.4641\n",
      "Epoch 3/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7722 - loss: 0.4524\n",
      "Epoch 4/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7765 - loss: 0.4616\n",
      "Epoch 5/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7806 - loss: 0.4465\n",
      "Epoch 6/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7771 - loss: 0.4533\n",
      "Epoch 7/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7852 - loss: 0.4432\n",
      "Epoch 8/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7672 - loss: 0.4603\n",
      "Epoch 9/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7636 - loss: 0.4605\n",
      "Epoch 10/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7843 - loss: 0.4493\n",
      "Epoch 11/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7860 - loss: 0.4393\n",
      "Epoch 12/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7729 - loss: 0.4548\n",
      "Epoch 13/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7774 - loss: 0.4527\n",
      "Epoch 14/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7789 - loss: 0.4531\n",
      "Epoch 15/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7835 - loss: 0.4371\n",
      "Epoch 16/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7661 - loss: 0.4629\n",
      "Epoch 17/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7626 - loss: 0.4727\n",
      "Epoch 18/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7741 - loss: 0.4459\n",
      "Epoch 19/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7729 - loss: 0.4559\n",
      "Epoch 20/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7815 - loss: 0.4497\n",
      "Epoch 21/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7741 - loss: 0.4524\n",
      "Epoch 22/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7692 - loss: 0.4552\n",
      "Epoch 23/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7776 - loss: 0.4474\n",
      "Epoch 24/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7829 - loss: 0.4471\n",
      "Epoch 25/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7732 - loss: 0.4513\n",
      "Epoch 26/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7782 - loss: 0.4496\n",
      "Epoch 27/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7771 - loss: 0.4498\n",
      "Epoch 28/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7670 - loss: 0.4600\n",
      "Epoch 29/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7822 - loss: 0.4410\n",
      "Epoch 30/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7726 - loss: 0.4500\n",
      "Epoch 31/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7796 - loss: 0.4438\n",
      "Epoch 32/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7802 - loss: 0.4390\n",
      "Epoch 33/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7838 - loss: 0.4492\n",
      "Epoch 34/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7803 - loss: 0.4454\n",
      "Epoch 35/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7731 - loss: 0.4577\n",
      "Epoch 36/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7772 - loss: 0.4620\n",
      "Epoch 37/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7810 - loss: 0.4471\n",
      "Epoch 38/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7952 - loss: 0.4209\n",
      "Epoch 39/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7838 - loss: 0.4409\n",
      "Epoch 40/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7808 - loss: 0.4434\n",
      "Epoch 41/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7808 - loss: 0.4484\n",
      "Epoch 42/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7870 - loss: 0.4380\n",
      "Epoch 43/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7830 - loss: 0.4425\n",
      "Epoch 44/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7770 - loss: 0.4545\n",
      "Epoch 45/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7803 - loss: 0.4477\n",
      "Epoch 46/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7678 - loss: 0.4530\n",
      "Epoch 47/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7763 - loss: 0.4458\n",
      "Epoch 48/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7843 - loss: 0.4388\n",
      "Epoch 49/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7882 - loss: 0.4381\n",
      "Epoch 50/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7800 - loss: 0.4472\n",
      "Epoch 51/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7851 - loss: 0.4406\n",
      "Epoch 52/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7771 - loss: 0.4585\n",
      "Epoch 53/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7717 - loss: 0.4575\n",
      "Epoch 54/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7846 - loss: 0.4468\n",
      "Epoch 55/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7829 - loss: 0.4450\n",
      "Epoch 56/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7715 - loss: 0.4575\n",
      "Epoch 57/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7819 - loss: 0.4513\n",
      "Epoch 58/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7881 - loss: 0.4344\n",
      "Epoch 59/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7832 - loss: 0.4398\n",
      "Epoch 60/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7851 - loss: 0.4509\n",
      "Epoch 61/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7850 - loss: 0.4479\n",
      "Epoch 62/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7844 - loss: 0.4387\n",
      "Epoch 63/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7879 - loss: 0.4401\n",
      "Epoch 64/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7871 - loss: 0.4381\n",
      "Epoch 65/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7806 - loss: 0.4416\n",
      "Epoch 66/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7758 - loss: 0.4406\n",
      "Epoch 67/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7845 - loss: 0.4483\n",
      "Epoch 68/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7787 - loss: 0.4515\n",
      "Epoch 69/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7789 - loss: 0.4443\n",
      "Epoch 70/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7709 - loss: 0.4615\n",
      "Epoch 71/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7814 - loss: 0.4379\n",
      "Epoch 72/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7778 - loss: 0.4487\n",
      "Epoch 73/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7892 - loss: 0.4346\n",
      "Epoch 74/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7797 - loss: 0.4436\n",
      "Epoch 75/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7893 - loss: 0.4311\n",
      "Epoch 76/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7725 - loss: 0.4511\n",
      "Epoch 77/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7773 - loss: 0.4514\n",
      "Epoch 78/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7884 - loss: 0.4381\n",
      "Epoch 79/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7902 - loss: 0.4349\n",
      "Epoch 80/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7861 - loss: 0.4417\n",
      "Epoch 81/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7733 - loss: 0.4549\n",
      "Epoch 82/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7829 - loss: 0.4406\n",
      "Epoch 83/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7799 - loss: 0.4439\n",
      "Epoch 84/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7807 - loss: 0.4494\n",
      "Epoch 85/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7809 - loss: 0.4490\n",
      "Epoch 86/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.7901 - loss: 0.4392\n",
      "Epoch 87/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7861 - loss: 0.4428\n",
      "Epoch 88/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7786 - loss: 0.4405\n",
      "Epoch 89/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7776 - loss: 0.4378\n",
      "Epoch 90/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7839 - loss: 0.4344\n",
      "Epoch 91/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7866 - loss: 0.4380\n",
      "Epoch 92/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7832 - loss: 0.4425\n",
      "Epoch 93/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7889 - loss: 0.4312\n",
      "Epoch 94/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7815 - loss: 0.4456\n",
      "Epoch 95/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7931 - loss: 0.4341\n",
      "Epoch 96/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7916 - loss: 0.4273\n",
      "Epoch 97/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7710 - loss: 0.4518\n",
      "Epoch 98/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7824 - loss: 0.4428\n",
      "Epoch 99/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7908 - loss: 0.4327\n",
      "Epoch 100/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7733 - loss: 0.4552\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_3_0, df_3_1, 0, 2037)\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "y_pred1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7778 - loss: 0.4649\n",
      "Epoch 2/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7881 - loss: 0.4572\n",
      "Epoch 3/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7712 - loss: 0.4658\n",
      "Epoch 4/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7815 - loss: 0.4641\n",
      "Epoch 5/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7793 - loss: 0.4626\n",
      "Epoch 6/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.7845 - loss: 0.4560\n",
      "Epoch 7/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7740 - loss: 0.4658\n",
      "Epoch 8/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7887 - loss: 0.4477\n",
      "Epoch 9/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7729 - loss: 0.4590\n",
      "Epoch 10/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7735 - loss: 0.4667\n",
      "Epoch 11/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7841 - loss: 0.4439\n",
      "Epoch 12/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7852 - loss: 0.4625\n",
      "Epoch 13/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7766 - loss: 0.4653\n",
      "Epoch 14/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7851 - loss: 0.4519\n",
      "Epoch 15/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7964 - loss: 0.4438\n",
      "Epoch 16/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7854 - loss: 0.4458\n",
      "Epoch 17/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7879 - loss: 0.4427\n",
      "Epoch 18/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7910 - loss: 0.4457\n",
      "Epoch 19/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7788 - loss: 0.4443\n",
      "Epoch 20/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7949 - loss: 0.4441\n",
      "Epoch 21/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7919 - loss: 0.4486\n",
      "Epoch 22/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7941 - loss: 0.4318\n",
      "Epoch 23/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7812 - loss: 0.4555\n",
      "Epoch 24/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.7796 - loss: 0.4512\n",
      "Epoch 25/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7861 - loss: 0.4444\n",
      "Epoch 26/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.7783 - loss: 0.4541\n",
      "Epoch 27/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7809 - loss: 0.4564\n",
      "Epoch 28/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7729 - loss: 0.4718\n",
      "Epoch 29/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7981 - loss: 0.4453\n",
      "Epoch 30/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7806 - loss: 0.4478\n",
      "Epoch 31/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7843 - loss: 0.4531\n",
      "Epoch 32/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7860 - loss: 0.4420\n",
      "Epoch 33/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7924 - loss: 0.4428\n",
      "Epoch 34/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7870 - loss: 0.4413\n",
      "Epoch 35/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7850 - loss: 0.4492\n",
      "Epoch 36/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7860 - loss: 0.4447\n",
      "Epoch 37/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7957 - loss: 0.4379\n",
      "Epoch 38/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7703 - loss: 0.4540\n",
      "Epoch 39/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7775 - loss: 0.4559\n",
      "Epoch 40/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7893 - loss: 0.4529\n",
      "Epoch 41/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7843 - loss: 0.4440\n",
      "Epoch 42/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7868 - loss: 0.4384\n",
      "Epoch 43/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7881 - loss: 0.4508\n",
      "Epoch 44/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7849 - loss: 0.4597\n",
      "Epoch 45/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7820 - loss: 0.4463\n",
      "Epoch 46/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7821 - loss: 0.4488\n",
      "Epoch 47/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7871 - loss: 0.4531\n",
      "Epoch 48/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7842 - loss: 0.4507\n",
      "Epoch 49/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7839 - loss: 0.4477\n",
      "Epoch 50/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7882 - loss: 0.4366\n",
      "Epoch 51/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7851 - loss: 0.4467\n",
      "Epoch 52/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7826 - loss: 0.4456\n",
      "Epoch 53/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.7844 - loss: 0.4544\n",
      "Epoch 54/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.7790 - loss: 0.4609\n",
      "Epoch 55/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7951 - loss: 0.4362\n",
      "Epoch 56/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7955 - loss: 0.4413\n",
      "Epoch 57/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7837 - loss: 0.4416\n",
      "Epoch 58/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7864 - loss: 0.4469\n",
      "Epoch 59/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7809 - loss: 0.4495\n",
      "Epoch 60/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7927 - loss: 0.4413\n",
      "Epoch 61/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7820 - loss: 0.4542\n",
      "Epoch 62/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7994 - loss: 0.4366\n",
      "Epoch 63/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7750 - loss: 0.4533\n",
      "Epoch 64/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7833 - loss: 0.4474\n",
      "Epoch 65/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7821 - loss: 0.4566\n",
      "Epoch 66/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7922 - loss: 0.4390\n",
      "Epoch 67/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7852 - loss: 0.4442\n",
      "Epoch 68/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7968 - loss: 0.4375\n",
      "Epoch 69/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7759 - loss: 0.4583\n",
      "Epoch 70/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7963 - loss: 0.4371\n",
      "Epoch 71/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7843 - loss: 0.4650\n",
      "Epoch 72/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7861 - loss: 0.4447\n",
      "Epoch 73/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7789 - loss: 0.4594\n",
      "Epoch 74/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7829 - loss: 0.4564\n",
      "Epoch 75/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7948 - loss: 0.4303\n",
      "Epoch 76/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7813 - loss: 0.4524\n",
      "Epoch 77/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7884 - loss: 0.4400\n",
      "Epoch 78/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7886 - loss: 0.4455\n",
      "Epoch 79/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7802 - loss: 0.4464\n",
      "Epoch 80/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7772 - loss: 0.4617\n",
      "Epoch 81/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7889 - loss: 0.4411\n",
      "Epoch 82/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7828 - loss: 0.4495\n",
      "Epoch 83/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7891 - loss: 0.4433\n",
      "Epoch 84/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7922 - loss: 0.4415\n",
      "Epoch 85/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7982 - loss: 0.4286\n",
      "Epoch 86/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7805 - loss: 0.4419\n",
      "Epoch 87/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7886 - loss: 0.4310\n",
      "Epoch 88/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.8010 - loss: 0.4261\n",
      "Epoch 89/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7849 - loss: 0.4470\n",
      "Epoch 90/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7906 - loss: 0.4402\n",
      "Epoch 91/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7957 - loss: 0.4451\n",
      "Epoch 92/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7888 - loss: 0.4421\n",
      "Epoch 93/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7865 - loss: 0.4474\n",
      "Epoch 94/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7865 - loss: 0.4451\n",
      "Epoch 95/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7869 - loss: 0.4430\n",
      "Epoch 96/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7769 - loss: 0.4591\n",
      "Epoch 97/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7848 - loss: 0.4427\n",
      "Epoch 98/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7963 - loss: 0.4215\n",
      "Epoch 99/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7978 - loss: 0.4357\n",
      "Epoch 100/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7993 - loss: 0.4305\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_3_0, df_3_1, 2037, 4074)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "y_pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7932 - loss: 0.4474\n",
      "Epoch 2/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7834 - loss: 0.4497\n",
      "Epoch 3/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7807 - loss: 0.4459\n",
      "Epoch 4/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7854 - loss: 0.4433\n",
      "Epoch 5/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7899 - loss: 0.4367\n",
      "Epoch 6/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7854 - loss: 0.4397\n",
      "Epoch 7/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7814 - loss: 0.4585\n",
      "Epoch 8/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7752 - loss: 0.4531\n",
      "Epoch 9/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7850 - loss: 0.4460\n",
      "Epoch 10/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7882 - loss: 0.4397\n",
      "Epoch 11/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7844 - loss: 0.4494\n",
      "Epoch 12/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7952 - loss: 0.4395\n",
      "Epoch 13/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7883 - loss: 0.4309\n",
      "Epoch 14/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8028 - loss: 0.4249\n",
      "Epoch 15/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7928 - loss: 0.4450\n",
      "Epoch 16/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7906 - loss: 0.4362\n",
      "Epoch 17/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7962 - loss: 0.4321\n",
      "Epoch 18/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7852 - loss: 0.4447\n",
      "Epoch 19/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7884 - loss: 0.4333\n",
      "Epoch 20/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7882 - loss: 0.4424\n",
      "Epoch 21/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7901 - loss: 0.4382\n",
      "Epoch 22/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7846 - loss: 0.4439\n",
      "Epoch 23/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7874 - loss: 0.4348\n",
      "Epoch 24/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7873 - loss: 0.4428\n",
      "Epoch 25/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7807 - loss: 0.4551\n",
      "Epoch 26/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7877 - loss: 0.4409\n",
      "Epoch 27/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7882 - loss: 0.4384\n",
      "Epoch 28/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7824 - loss: 0.4373\n",
      "Epoch 29/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7994 - loss: 0.4276\n",
      "Epoch 30/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7810 - loss: 0.4479\n",
      "Epoch 31/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7868 - loss: 0.4438\n",
      "Epoch 32/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7795 - loss: 0.4480\n",
      "Epoch 33/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7838 - loss: 0.4417\n",
      "Epoch 34/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7847 - loss: 0.4516\n",
      "Epoch 35/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.7838 - loss: 0.4427\n",
      "Epoch 36/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7883 - loss: 0.4243\n",
      "Epoch 37/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7750 - loss: 0.4472\n",
      "Epoch 38/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7899 - loss: 0.4374\n",
      "Epoch 39/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7863 - loss: 0.4352\n",
      "Epoch 40/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.7907 - loss: 0.4313\n",
      "Epoch 41/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7901 - loss: 0.4398\n",
      "Epoch 42/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7858 - loss: 0.4506\n",
      "Epoch 43/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7906 - loss: 0.4414\n",
      "Epoch 44/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7866 - loss: 0.4431\n",
      "Epoch 45/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7873 - loss: 0.4390\n",
      "Epoch 46/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7912 - loss: 0.4371\n",
      "Epoch 47/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7900 - loss: 0.4334\n",
      "Epoch 48/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7912 - loss: 0.4374\n",
      "Epoch 49/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7890 - loss: 0.4404\n",
      "Epoch 50/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7833 - loss: 0.4410\n",
      "Epoch 51/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7944 - loss: 0.4380\n",
      "Epoch 52/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7898 - loss: 0.4382\n",
      "Epoch 53/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7968 - loss: 0.4336\n",
      "Epoch 54/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7958 - loss: 0.4274\n",
      "Epoch 55/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7994 - loss: 0.4258\n",
      "Epoch 56/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.7928 - loss: 0.4328\n",
      "Epoch 57/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7921 - loss: 0.4406\n",
      "Epoch 58/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7967 - loss: 0.4386\n",
      "Epoch 59/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.7881 - loss: 0.4551\n",
      "Epoch 60/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7834 - loss: 0.4418\n",
      "Epoch 61/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.7947 - loss: 0.4276\n",
      "Epoch 62/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7928 - loss: 0.4366\n",
      "Epoch 63/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7981 - loss: 0.4296\n",
      "Epoch 64/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7994 - loss: 0.4366\n",
      "Epoch 65/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8034 - loss: 0.4239\n",
      "Epoch 66/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7804 - loss: 0.4466\n",
      "Epoch 67/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.8072 - loss: 0.4124\n",
      "Epoch 68/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7849 - loss: 0.4437\n",
      "Epoch 69/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7990 - loss: 0.4251\n",
      "Epoch 70/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8003 - loss: 0.4173\n",
      "Epoch 71/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7981 - loss: 0.4274\n",
      "Epoch 72/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8062 - loss: 0.4136\n",
      "Epoch 73/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7942 - loss: 0.4427\n",
      "Epoch 74/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7858 - loss: 0.4438\n",
      "Epoch 75/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7870 - loss: 0.4355\n",
      "Epoch 76/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8052 - loss: 0.4222\n",
      "Epoch 77/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7867 - loss: 0.4411\n",
      "Epoch 78/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7875 - loss: 0.4351\n",
      "Epoch 79/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7915 - loss: 0.4388\n",
      "Epoch 80/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7933 - loss: 0.4309\n",
      "Epoch 81/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7890 - loss: 0.4316\n",
      "Epoch 82/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.7909 - loss: 0.4331\n",
      "Epoch 83/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.8060 - loss: 0.4127\n",
      "Epoch 84/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7951 - loss: 0.4249\n",
      "Epoch 85/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7915 - loss: 0.4330\n",
      "Epoch 86/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7912 - loss: 0.4486\n",
      "Epoch 87/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7950 - loss: 0.4274\n",
      "Epoch 88/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.7933 - loss: 0.4353\n",
      "Epoch 89/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7962 - loss: 0.4307\n",
      "Epoch 90/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7914 - loss: 0.4420\n",
      "Epoch 91/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7924 - loss: 0.4413\n",
      "Epoch 92/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7946 - loss: 0.4303\n",
      "Epoch 93/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7878 - loss: 0.4364\n",
      "Epoch 94/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.7932 - loss: 0.4238\n",
      "Epoch 95/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.7875 - loss: 0.4429\n",
      "Epoch 96/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7949 - loss: 0.4351\n",
      "Epoch 97/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7983 - loss: 0.4373\n",
      "Epoch 98/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7939 - loss: 0.4277\n",
      "Epoch 99/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.7997 - loss: 0.4302\n",
      "Epoch 100/100\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.7959 - loss: 0.4360\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_3_0, df_3_1, 4074, 6111)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "y_pred3 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7959 - loss: 0.4475\n",
      "Epoch 2/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.7900 - loss: 0.4492\n",
      "Epoch 3/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7900 - loss: 0.4432\n",
      "Epoch 4/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7884 - loss: 0.4409\n",
      "Epoch 5/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7971 - loss: 0.4331\n",
      "Epoch 6/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7871 - loss: 0.4466\n",
      "Epoch 7/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.7868 - loss: 0.4368\n",
      "Epoch 8/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.7952 - loss: 0.4430\n",
      "Epoch 9/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7895 - loss: 0.4418\n",
      "Epoch 10/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7937 - loss: 0.4373\n",
      "Epoch 11/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7861 - loss: 0.4542\n",
      "Epoch 12/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7889 - loss: 0.4445\n",
      "Epoch 13/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7867 - loss: 0.4380\n",
      "Epoch 14/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7891 - loss: 0.4476\n",
      "Epoch 15/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7894 - loss: 0.4460\n",
      "Epoch 16/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7916 - loss: 0.4430\n",
      "Epoch 17/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7996 - loss: 0.4212\n",
      "Epoch 18/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7947 - loss: 0.4370\n",
      "Epoch 19/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7909 - loss: 0.4304\n",
      "Epoch 20/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7921 - loss: 0.4370\n",
      "Epoch 21/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7850 - loss: 0.4401\n",
      "Epoch 22/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.7987 - loss: 0.4453\n",
      "Epoch 23/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7989 - loss: 0.4240\n",
      "Epoch 24/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7928 - loss: 0.4277\n",
      "Epoch 25/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step - accuracy: 0.7842 - loss: 0.4464\n",
      "Epoch 26/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.8043 - loss: 0.4185\n",
      "Epoch 27/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.7999 - loss: 0.4310\n",
      "Epoch 28/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8014 - loss: 0.4293\n",
      "Epoch 29/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7901 - loss: 0.4396\n",
      "Epoch 30/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.8046 - loss: 0.4205\n",
      "Epoch 31/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7896 - loss: 0.4332\n",
      "Epoch 32/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7864 - loss: 0.4354\n",
      "Epoch 33/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8001 - loss: 0.4379\n",
      "Epoch 34/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.7954 - loss: 0.4402\n",
      "Epoch 35/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.7890 - loss: 0.4428\n",
      "Epoch 36/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.8008 - loss: 0.4278\n",
      "Epoch 37/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.7998 - loss: 0.4287\n",
      "Epoch 38/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.7888 - loss: 0.4305\n",
      "Epoch 39/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.7914 - loss: 0.4344\n",
      "Epoch 40/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7892 - loss: 0.4492\n",
      "Epoch 41/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7929 - loss: 0.4275\n",
      "Epoch 42/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7905 - loss: 0.4308\n",
      "Epoch 43/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.7966 - loss: 0.4282\n",
      "Epoch 44/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.8104 - loss: 0.4257\n",
      "Epoch 45/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7963 - loss: 0.4278\n",
      "Epoch 46/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7929 - loss: 0.4431\n",
      "Epoch 47/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7943 - loss: 0.4375\n",
      "Epoch 48/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7863 - loss: 0.4418\n",
      "Epoch 49/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.8020 - loss: 0.4246\n",
      "Epoch 50/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7942 - loss: 0.4353\n",
      "Epoch 51/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7985 - loss: 0.4311\n",
      "Epoch 52/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7838 - loss: 0.4380\n",
      "Epoch 53/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7992 - loss: 0.4327\n",
      "Epoch 54/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7827 - loss: 0.4383\n",
      "Epoch 55/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7967 - loss: 0.4347\n",
      "Epoch 56/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.7995 - loss: 0.4219\n",
      "Epoch 57/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.7992 - loss: 0.4293\n",
      "Epoch 58/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.7954 - loss: 0.4369\n",
      "Epoch 59/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.8020 - loss: 0.4334\n",
      "Epoch 60/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.8040 - loss: 0.4299\n",
      "Epoch 61/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7947 - loss: 0.4403\n",
      "Epoch 62/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7876 - loss: 0.4441\n",
      "Epoch 63/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7881 - loss: 0.4365\n",
      "Epoch 64/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7897 - loss: 0.4327\n",
      "Epoch 65/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7948 - loss: 0.4290\n",
      "Epoch 66/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step - accuracy: 0.7982 - loss: 0.4346\n",
      "Epoch 67/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8002 - loss: 0.4199\n",
      "Epoch 68/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7931 - loss: 0.4443\n",
      "Epoch 69/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7939 - loss: 0.4379\n",
      "Epoch 70/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7934 - loss: 0.4435\n",
      "Epoch 71/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7917 - loss: 0.4340\n",
      "Epoch 72/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8019 - loss: 0.4253\n",
      "Epoch 73/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7872 - loss: 0.4366\n",
      "Epoch 74/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7945 - loss: 0.4356\n",
      "Epoch 75/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.8032 - loss: 0.4183\n",
      "Epoch 76/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7870 - loss: 0.4394\n",
      "Epoch 77/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7977 - loss: 0.4296\n",
      "Epoch 78/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.7989 - loss: 0.4168\n",
      "Epoch 79/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7981 - loss: 0.4261\n",
      "Epoch 80/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.8004 - loss: 0.4286\n",
      "Epoch 81/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7917 - loss: 0.4333\n",
      "Epoch 82/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8003 - loss: 0.4207\n",
      "Epoch 83/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7944 - loss: 0.4340\n",
      "Epoch 84/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7887 - loss: 0.4339\n",
      "Epoch 85/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8027 - loss: 0.4242\n",
      "Epoch 86/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7903 - loss: 0.4389\n",
      "Epoch 87/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.7887 - loss: 0.4352\n",
      "Epoch 88/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7939 - loss: 0.4300\n",
      "Epoch 89/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.7999 - loss: 0.4223\n",
      "Epoch 90/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7957 - loss: 0.4224\n",
      "Epoch 91/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7891 - loss: 0.4314\n",
      "Epoch 92/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.7947 - loss: 0.4276\n",
      "Epoch 93/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.8010 - loss: 0.4238\n",
      "Epoch 94/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.7980 - loss: 0.4302\n",
      "Epoch 95/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300us/step - accuracy: 0.7879 - loss: 0.4394\n",
      "Epoch 96/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8030 - loss: 0.4255\n",
      "Epoch 97/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8023 - loss: 0.4302\n",
      "Epoch 98/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.7992 - loss: 0.4265\n",
      "Epoch 99/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.8000 - loss: 0.4290\n",
      "Epoch 100/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.7995 - loss: 0.4273\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_3_0, df_3_1, 6111, 7963)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "y_pred4= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i] + y_pred4[i]\n",
    "    if n_ones<2:\n",
    "        y_pred_final[i] = 0\n",
    "    else:\n",
    "        y_pred_final[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1593\n",
      "           1       0.77      0.82      0.79      1593\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_pred and y_test are defined\n",
    "# y_pred is the predicted labels and y_test is the true labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "# Plot the confusion matrix using seaborn's heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
